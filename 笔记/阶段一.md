# 阶段一

## 基本概念 与 KafkaAdmin

### 1. 核心组件解析

|**组件名称**|**角色**|**解释**||||
| --| --------------------------| ---------------------------------------------------------------------------------------------------------------------------------------------------| --| --| --|
|**Broker**|Kafka 集群的​**服务器节点**。|每个 Broker 都是一个 Kafka 进程。一个集群由一个或多个 Broker 组成。Broker 负责存储 Topic 的分区数据、处理生产者和消费者的请求，以及执行副本同步。||||
|**Topic (主题)**|消息的**类别**或​**逻辑队列**。|生产者向特定 Topic 发布消息，消费者订阅特定 Topic 来消费消息。它是 Kafka 对消息进行分类和管理的单位。||||
|**Partition (分区)**|Topic 的​**物理存储单元**，实现并行。|每个 Topic 由一个或多个 Partition 组成。消息被追加到 Partition 中，且在 Partition 内是**有序且不可变**的。Partition 是 Kafka 实现**负载均衡**和**高吞吐量**的关键。||||
|**Producer (生产者)**|​**消息的发送方**。|负责创建消息并将其发布到 Kafka 集群的指定 Topic 的特定 Partition 中。||||
|**Consumer (消费者)**|​**消息的接收方**。|负责订阅 Topic 并消费消息。多个消费者可以组成一个​**消费组 (Consumer Group)** ​，共同消费一个 Topic 的消息，从而实现​**并行消费**。||||

> ​**关键关系**：
>
> 1. 一个 Topic 由多个 Partition 组成。
> 2. Partition 分布在不同的 Broker 上。
> 3. 每个 Partition 都有一个 **Leader 副本**和零或多个 ​**Follower 副本**，它们用于数据冗余和容错。

---

### 2. Kafka 的持久化机制：Log Segments

Kafka 消息的持久化依赖于其独特的文件存储结构——​**日志 (Log) 结构**​，它以 **Log Segments** 的形式存储在磁盘上。

#### 核心结构

每个 Partition 对应 Broker 磁盘上的一个文件夹。这个文件夹内包含一系列有序、不可变的 ​**Log Segment 文件对**：

1. ​ **​`.log`​**​ **文件 (数据文件)** ：实际存储消息的二进制数据。
2. ​ **​`.index`​**​ **文件 (稀疏索引文件)** ​：存储消息的 ​**Offset**​（偏移量）与消息在 `.log`​ 文件中的​**物理位置**（文件偏移量）的映射关系。
3. ​ **​`.timeindex`​**​ **文件 (时间戳索引文件)** ​：存储消息的 **时间戳** 与 Offset 的映射关系，用于按时间查找。

#### Log Segment 的工作方式

- ​**追加写入**​：所有新消息总是以追加（append-only）的方式写入到当前活动的 **活跃 Segment** 文件中。
- ​**文件切换 (Segment Roll)** ：当活跃 Segment 文件大小达到预设阈值（例如 1GB）或者时间达到阈值后，Kafka 会关闭该文件，创建一个新的 Segment 文件作为活跃 Segment。
- ​**基于 Offset 查找**：消费者通过 Offset 确定从哪里开始消费。Kafka 利用索引文件，通过二分查找快速定位到包含该 Offset 的 Segment 文件，然后通过索引文件找到消息在数据文件中的确切位置，实现快速读取。
- **Log Compaction (日志压缩)** ：针对某些需要保留最新状态的 Topic（例如配置存储），Kafka 支持日志压缩，它会删除同一 Key 的旧消息，只保留最新的消息记录。

---

### 3. 为什么 Kafka 速度快？（高性能机制）

Kafka 能够实现高吞吐量和低延迟，主要归功于以下几大设计机制：

#### 3.1 顺序读写（Sequential I/O）

- ​**顺序追加**​：Kafka 将消息数据以**顺序追加**的方式写入磁盘的 Log Segment 文件。
- ​**机械磁盘优化**：顺序读写避免了磁盘寻道时间，比随机 I/O 效率高得多。对于机械硬盘而言，顺序读写速度几乎可以与内存读写速度相媲美。

#### 3.2 零拷贝（Zero-Copy）技术

- ​**避免数据冗余复制**​：在 Broker 将消息从磁盘文件传输到网络套接字（Socket）发送给消费者的过程中，Kafka 采用 **零拷贝** 技术。
- ​**传统 I/O**：数据需要在内核缓冲区和用户缓冲区之间进行多次复制。
- ​**零拷贝**​：利用操作系统的 `sendfile()`​ 或 `transferTo()`​ 方法，数据直接从文件系统的页缓存（Page Cache）传输到网络，​**避免了 CPU 参与的数据复制，显著降低了延迟和 CPU 负载**。

#### 3.3 批量发送 (Batching)

- ​**生产者优化**​：生产者不会立即发送每条消息，而是将多条消息收集在本地缓冲区，形成一个​**消息批次 (Batch)** ，然后一次性发送给 Broker。
- ​**减少网络开销**：批次发送显著减少了网络往返次数 (RTT) 和 I/O 操作次数。

#### 3.4 文件系统页缓存 (Page Cache)

- ​**利用内存**​：Kafka 大量依赖操作系统的**页缓存**来缓存消息数据。
- ​**快速读写**​：当消费者请求消息时，如果数据已经在页缓存中，Kafka 可以直接从内存中读取，速度极快。即使需要写入磁盘，操作系统也会先写入页缓存，然后由后台线程异步写入磁盘（`fsync`）。

---

### 4. Kafka Admin Client 的使用

在 Spring Boot 中，我们通常使用 `org.springframework.kafka.core.KafkaAdmin`​ 或直接操作其内部的 `AdminClient` 来进行 Topic、分区、配置等资源的程序化管理。

#### 4.1 自动配置与 `KafkaAdmin`

如模块一的回复所示，Spring Boot 会自动配置 `KafkaAdmin`​ Bean。您只需定义 `NewTopic` Bean，Spring Boot 就会自动完成创建 Topic 的任务。

#### 4.2 进阶：直接使用 `AdminClient` 进行管理操作

如果您需要执行更复杂的管理操作（例如，删除 Topic、修改配置、查询集群信息），您需要通过 `KafkaAdmin`​ 获取或配置 `AdminClient`。

**步骤：**

1. **注入** **​`KafkaAdmin`​**​  **(或直接注入** **​`AdminClient`​**​ **)**
2. **执行管理操作**

```java
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.DescribeTopicsResult;
import org.apache.kafka.clients.admin.NewTopic;
import org.springframework.kafka.core.KafkaAdmin;
import org.springframework.stereotype.Service;

import java.util.Collections;
import java.util.concurrent.ExecutionException;

@Service
public class KafkaAdminService {

    private final AdminClient adminClient;

    // Spring Boot 启动时会自动配置 KafkaAdmin，并可以通过它获取 AdminClient
    public KafkaAdminService(KafkaAdmin kafkaAdmin) {
        // 从 KafkaAdmin 的配置中构建 AdminClient
        this.adminClient = AdminClient.create(kafkaAdmin.getConfigurationProperties());
    }

    /**
     * 编程创建 Topic (如果需要动态创建)
     */
    public void createTopic(String topicName, int partitions, short replicationFactor) throws ExecutionException, InterruptedException {
        NewTopic newTopic = new NewTopic(topicName, partitions, replicationFactor);
        
        // 调用 createTopics 方法，并阻塞等待结果 (生产中推荐异步处理 Future)
        adminClient.createTopics(Collections.singletonList(newTopic)).all().get();
        System.out.println("✅ Topic '" + topicName + "' 创建成功!");
    }

    /**
     * 删除指定的 Topic
     */
    public void deleteTopic(String topicName) throws ExecutionException, InterruptedException {
        adminClient.deleteTopics(Collections.singletonList(topicName)).all().get();
        System.out.println("🗑️ Topic '" + topicName + "' 删除成功!");
    }

    /**
     * 查看 Topic 的详细信息
     */
    public void describeTopic(String topicName) throws ExecutionException, InterruptedException {
        DescribeTopicsResult result = adminClient.describeTopics(Collections.singletonList(topicName));
        
        // 阻塞获取结果
        result.allTopicNames().get().forEach((name, description) -> {
            System.out.println("📋 Topic: " + name);
            description.partitions().forEach(partition -> {
                System.out.println("   - Partition " + partition.partition() 
                                    + ", Leader: " + partition.leader().id() 
                                    + ", Replicas: " + partition.replicas().size());
            });
        });
    }

    // 应用程序关闭时，应关闭 AdminClient
    // @PreDestroy
    // public void close() {
    //     adminClient.close();
    // }
}
```

‍

---

‍

‍

‍

#### 

#### 5. topic 的两种创建方式

1. 在`config`类里，使用 Bean 创建

    ```java
        @Bean
        public NewTopic kafkaDemoTopic() {
            return new NewTopic("kafka-demo", 3, (short) 1); // 主题名，分区数，副本因子
        }
    ```

2. service层实现

    ```java
    @Slf4j
    @Service
    public class TopicManagementService {

        @Autowired
        private KafkaAdmin kafkaAdmin;

        // 创建新的 Topic
        public boolean createTopic(String topicName, int partitions, short replicationFactor) {
            AdminClient adminClient = AdminClient.create(kafkaAdmin.getConfigurationProperties());
            try {
                NewTopic newTopic = new NewTopic(topicName, partitions, replicationFactor);
                CreateTopicsResult result = adminClient.createTopics(Collections.singletonList(newTopic));
                result.all().get(); // 等待创建完成
                log.info("成功创建 Topic：{}", topicName);
                return true;
            } catch (Exception e) {
                log.error("创建 Topic 失败：{}", e.getMessage());
                return false;
            } finally {
                adminClient.close();
            }
        }

        // 删除 Topic
        public boolean deleteTopic(String topicName) {
            AdminClient adminClient = AdminClient.create(kafkaAdmin.getConfigurationProperties());
            try {
                DeleteTopicsResult result = adminClient.deleteTopics(Collections.singletonList(topicName));
                result.all().get(); // 等待删除完成
                log.info("成功删除 Topic: {}", topicName);
                return true;
            } catch (Exception e) {
                log.error("删除 Topic 失败: {}", e.getMessage());
                return false;
            } finally {
                adminClient.close();
            }
        }
    }
    ```

‍

## Kafka 消息发送核心机制

### 1. 同步发送 (Sync) vs. 异步发送 (Async)

#### 概念差异

|**特性**|**异步发送 (Async)**|**同步发送 (Sync)**||||
| --| --------------------------------------------------------------------------| ------------------------------------------------| --| --| --|
|**发送方式**|生产者将消息发送到​**本地缓冲区**，并立即返回。由独立的 I/O 线程批量发送到 Broker。|生产者发送消息后，**必须等待 Broker 的确认 (ACK)** 后才能继续发送下一条消息。||||
|**性能/吞吐量**|​**高**。利用了批量发送，显著提高了吞吐量。|​**低**。每条消息都需要等待网络往返延迟。||||
|**延迟**|​**低**。消息发送方不会被 Broker 确认阻塞。|​**高**。受网络延迟和 Broker 处理时间的直接影响。||||
|**可靠性**|生产者需要实现回调函数 (`Callback`) 来处理成功或失败，可靠性通过异步机制保证。|直观，若方法调用抛出异常，则发送失败。||||

#### 实际应用

在 **Kafka 0.8.2** 之后的版本中，​**Kafka 生产者客户端默认且推荐使用异步发送**。

- ​**同步发送**​：实际上是通过调用异步发送 API，然后使用 `Future.get()`​ 方法**阻塞**发送线程，直到 Broker 返回响应。
- **异步发送**：调用 `producer.send(record, callback)`​ 方法，立即返回，通过回调函数来处理结果。这是生产环境中**首选**的方式，以追求高吞吐量。

---

### <span id="20251031191717-qipdd9w" style="display: none;"></span>2. Acks 配置（0, 1, All）对性能和持久性的影响

​`acks`​ 配置决定了生产者发送的消息需要等待多少个 Broker 副本的确认，这是权衡 **可靠性 (持久性)**  与 **性能 (吞吐量/延迟)**  的核心参数。

|**acks 值**|**持久性/可靠性**|**性能/吞吐量**|**工作原理**|||||
| ---------| ----------------| ------------| ------------------------------------------------------------------------------------------------------------------------------------| --| --| --| --|
|**0**|**最低**(可能丢失数据)|**最高**(最低延迟)|生产者发送后不等待任何 Broker 响应，立刻认为发送成功。Broker 宕机或消息丢失生产者不会知晓。|||||
|**1**|**中等**(Leader 确认)|**中等**|生产者等待**Leader 副本**成功写入消息后即返回。如果 Leader 写入成功后但在 Follower 复制前宕机，消息可能丢失。|||||
|**all**(或 -1)|**最高**(最高持久性)|**最低**(最高延迟)|生产者等待 Leader 副本和**所有同步副本 (ISR)** 都成功写入消息后才返回。只要 ISR 中至少有一个副本存活，消息就不会丢失（假设副本因子\$\\ge 2\$）。|||||

> 🔑 ​**最佳实践**​：在对数据完整性要求极高的场景（例如金融交易、订单系统），应配置 `acks=all`​。在对丢失少量数据可以容忍，但对吞吐量要求更高的场景（例如日志收集、监控指标），可以考虑 `acks=1`。

---

### 3. 分区器 (Partitioner) 的作用和定制

#### 作用

分区器决定了生产者发送的每条消息将写入到 Topic 的哪一个分区 (Partition)。其核心作用是：

1. ​**负载均衡**：将消息均匀地分布到所有分区上，避免数据倾斜。
2. ​**保证局部有序性**：同一 Key 的消息总是发送到同一个分区，确保这些消息在消费时的相对顺序。

#### 默认分区器 (`DefaultPartitioner`) 机制

- ​**带 Key 的消息**​：对 Key 进行 Hash 运算（默认是 MurmurHash2），然后将 Hash 值对分区数取模 (`hash(key) % num_partitions`)，以此确定分区。
- ​**无 Key 的消息**​：采用 **轮询 (Round-Robin)**  机制，或在批次大小满时随机选择分区。

#### 定制分区器

如果您需要基于自定义业务逻辑来决定消息的分区（例如，按地理位置、按用户类型等），您可以定制分区器。

**定制步骤：**

1. 实现 `org.apache.kafka.clients.producer.Partitioner` 接口。
2. 实现 `partition()` 方法，该方法接收 Topic、Key、Value 等信息，并返回一个整数表示目标分区号。
3. 在生产者配置中，通过 `partitioner.class` 参数指定您自定义的分区器全限定类名。

---

## 消费者、消费组与可靠性

### 1. Consumer Group 和 Partition 消费关系

**消费者组（Consumer Group）**  是 Kafka 实现消息**负载均衡**和**容错**的核心机制。

#### 1.1 核心原则：独占性

- ​**消费关系**​：在同一个 **Consumer Group** 内，一个 Partition 只能被该组内的一个 Consumer 实例消费。
- ​**负载均衡**：一个 Topic 的所有 Partition 会尽量均匀地分配给 Consumer Group 内的所有 Consumer 实例。

  - 如果 ​**Consumer 数量 ≤ Partition 数量**：每个 Consumer 实例会负责消费一个或多个 Partition。
  - 如果 ​**Consumer 数量**  **&gt;**  **Partition 数量**​：**多余的 Consumer 实例将处于空闲状态，因为一个 Partition 最多只能被一个 Consumer 消费**。

#### 1.2 顺序性保证

- ​**分区内有序**​：Kafka **只保证**同一个 Partition 内的消息是有序的。
- ​**全局无序**：跨多个 Partition 的消息是无法保证严格的全局顺序的。

>  **🎯 总结：**  要提高消费者的并行度，必须增加 Topic 的 Partition 数量；要保证相关消息的消费顺序，必须确保它们被发送到同一个 Partition (例如使用相同的 Key)。

#### 1.3 消费组的分配与 Rebalance (重平衡)

当 Consumer Group 内的成员发生变化时（例如有 Consumer 实例加入、离开或宕机），Kafka 会触发 **Rebalance** 过程：

1. ​**停止消费**：Group 内所有 Consumer 停止消费，并提交当前的 Offset。
2. ​**重新分配**​：新的 **Group Leader** 负责计算 Partition 的新分配方案。
3. **恢复消费**：Group 内的 Consumer 按照新方案获取分配给自己的 Partition，并从上一次提交的 Offset 处恢复消费。

注：重平衡非常消耗性能，应该尽量避免

---

### 2. Offset（偏移量）的意义与提交机制

#### 2.1 Offset 的意义

**Offset** 是一个​**单调递增的整数**，它唯一标识了 Partition 内的每一条消息。

- ​**作用**：消费者通过记录和提交它已经成功处理的下一条消息的 Offset，来标记自己的消费进度。
- ​**存储**​：消费者提交的 Offset 默认存储在一个特殊的内部 Topic：`__consumer_offsets` 中。

#### 2.2 Offset 提交机制

Offset 提交机制是影响 Kafka 消费可靠性的关键。

|**提交类型**|**配置参数**|**触发时机**|**可靠性**|**性能**|**丢失/重复风险**|||||||
|**自动提交**|​`enable.auto.commit=true`|按照`auto.commit.interval.ms`(默认 5 秒) 的间隔，在后台自动提交 Offset。|低|高|​**高**。如果在提交前消费者崩溃，Offset 未更新，重启后会从旧 Offset 开始，导致重复消费。|||||||
|**手动提交**|​`enable.auto.commit=false`|由应用程序代码在**消息处理成功后**主动调用`commitSync()`​或`commitAsync()`方法提交。|高|低/中|​**低**。保证了消息处理成功和 Offset 提交的原子性（或接近原子性）。|||||||
| --| --| --| --| --| --| -----------------------------| ----------------------| ----------------------| ----------------------| ----------------------| ----------------------|

#### 2.3 手动提交的两种方式

- ​**同步提交 (**​**​`commitSync()`​** ​ **)** ​：提交当前消费到的 Offset，API 调用会​**阻塞**，直到 Broker 返回提交成功的响应。

  - ​**优点**：提交可靠性高。
  - ​**缺点**：会降低 Consumer 的吞吐量。
- ​**异步提交 (**​**​`commitAsync()`​** ​ **)** ：发送提交请求后立即返回，不会等待 Broker 的响应。

  - ​**优点**：不会阻塞，吞吐量高。
  - ​**缺点**：如果提交失败，默认不会重试，可能导致 Offset 提交不精确。通常需要配合回调函数处理异常。

> ​ **🔑 最佳实践**​：​**手动异步提交配合同步提交**。在正常消费时使用异步提交以提高性能；在 Consumer 即将关闭或 Rebalance 发生前，使用同步提交来确保准确性。

---

### 3. 消息重复消费 (At Least Once) 的处理

Kafka 的设计默认提供 **At Least Once (至少一次)**  的语义，这意味着：

> 消息​**不会丢失**​，但有​**可能被重复消费**。

#### 重复消费发生的原因

主要发生在消费者崩溃或 Rebalance 期间：

1. Consumer 成功处理了消息 \$N\$。
2. 在 Consumer 提交 \$N\$ 的 Offset 之前，它崩溃了（或者发生了 Rebalance）。
3. 新的或重启的 Consumer 从上次成功提交的 Offset (\$N-1\$) 处开始消费。
4. 消息 \$N\$ 会被再次拉取和处理，导致重复消费。

#### 幂等性（Idempotence）与去重方案

处理重复消费的业界标准方案是确保业务操作具有​**幂等性**。

​**幂等性 (Idempotence)** ：指多次执行同一操作，产生的结果与执行一次操作的结果是相同的。

**实践方案：**

1. ​**数据库去重（常用）** ：

    - 在消息体中包含一个​**全局唯一的业务 ID**（例如订单号、交易流水号）。
    - 在消费者处理消息时，将该业务 ID 记录到数据库的**唯一索引字段**中。
    - 如果插入成功，则处理业务逻辑；如果插入失败（因为唯一键冲突），则说明消息是重复的，直接跳过处理。
2. ​**使用 Kafka 事务 (Transaction)** ：

    - Kafka 提供了 Producer 的​**幂等性**​（保证生产者发送的消息不重复）和跨多个 Topic/Partition 的​**事务**​（保证**Exactly Once** 语义）。
    - 对于简单的消息处理，启用 Producer 的幂等性 (`enable.idempotence=true`) 就能解决生产者重复发送导致的重复消费问题。
3. ​**使用外部存储去重（Redis）** ：

    - 将业务 ID 作为 Key 存入 Redis，并设置过期时间。
    - 处理消息前先查询 Redis，如果 Key 存在则跳过。

---

## **序列化与数据格式**

### 1. Serializer 和 Deserializer 的原理

Kafka 消息在网络传输和磁盘存储时，必须是字节数组 (`byte[]`) 的形式，以便于跨平台、跨语言传输。

#### 1.1 核心原理

- ​**序列化器 (Serializer)** ：

  - ​**作用**​：在 ​**Producer 端**​，将应用程序中的 **Java/Scala 对象** 转换成 Kafka 协议所需的原始**字节数组** (`byte[]`)。
  - ​**实现**​：Producer 客户端需要配置 `key.serializer`​ 和 `value.serializer`​。它实现了 `org.apache.kafka.common.serialization.Serializer`​ 接口中的 `serialize(String topic, T data)` 方法。
- ​**反序列化器 (Deserializer)** ：

  - ​**作用**​：在 ​**Consumer 端**​，将从 Broker 拉取到的**字节数组** (`byte[]`​) 转换回应用程序所需的 ​**Java/Scala 对象**。
  - ​**实现**​：Consumer 客户端需要配置 `key.deserializer`​ 和 `value.deserializer`​。它实现了 `org.apache.kafka.common.serialization.Deserializer`​ 接口中的 `deserialize(String topic, byte[] data)` 方法。

#### 1.2 为什么必须使用序列化/反序列化？

1. ​**网络传输要求**：网络协议只能传输原始的字节数据流。
2. ​**跨语言通信**​：Kafka 集群和客户端可能由不同的语言编写（Java, Python, Go, C++ 等），序列化提供了一种​**统一的数据交换格式**。
3. ​**磁盘存储**：Kafka Broker 存储在磁盘上的也是字节数组。

#### 1.3 常见的序列化器

Kafka 客户端自带了一些简单的序列化器：

- ​`StringSerializer/StringDeserializer` (使用 UTF-8 编码)
- ​`IntegerSerializer/IntegerDeserializer`
- ​`ByteArraySerializer/ByteArrayDeserializer`
- ​`JsonSerializer/JsonDeserializer` (需要依赖第三方库，例如 Spring Kafka 提供的)

### 2. 为什么要用 Avro/Protobuf 等模式定义？

虽然 JSON 和 Java 默认的序列化 (如 `Serializable`​ 或 Spring Kafka 的 `JsonSerializer`) 方便易用，但在复杂的、长期运行的分布式系统中，它们存在严重的缺陷。

使用 ​**Avro**​、**Protobuf (Protocol Buffers)**  或 **Thrift** 等**数据模式定义语言 (Schema Definition Language, SDL)**  是解决这些问题的标准方案。

#### 2.1 解决的问题一：模式演化与兼容性

这是使用模式定义的最主要原因。

- ​**问题**​：当您向消息结构中添加或删除字段时（即​**模式演化**），老版本的 Consumer 还能否正确解析新版本的 Producer 发送的消息？

  - ​**JSON/默认序列化**：兼容性差。如果您删除了一个字段，老 Consumer 可能会因为找不到该字段而抛出异常；如果您添加了一个字段，老 Consumer 可能会忽略，但如果数据结构调整较大，仍可能导致反序列化失败。
- ​**Avro/Protobuf 的优势**​：它们在设计上内置了**向前/向后兼容性**的支持。

  - ​**向前兼容 (Forward Compatibility)** ：新 Producer 发送的消息，老 Consumer 仍能读取。
  - ​**向后兼容 (Backward Compatibility)** ：老 Producer 发送的消息，新 Consumer 仍能读取。
  - ​**实现方式**​：通过严格的规则（如：只允许添加带默认值的新字段，不允许删除字段），并在序列化数据中嵌入或引用**模式 ID** 来确保。

#### 2.2 解决的问题二：数据冗余与存储效率

- ​**JSON/XML**：基于文本，包含了大量的字段名（Key）作为元数据，导致数据量大，网络传输和存储成本高。
- ​**Avro/Protobuf 的优势**​：它们是​**紧凑的二进制格式**​。在序列化时，它们只传输字段的​**值**​，而将字段名等元数据信息保存在**模式**中。

  - ​**结果**：消息体更小，传输效率更高，Kafka 的存储空间占用更少。

#### 2.3 解决的问题三：跨语言模式校验与一致性

- ​**问题**：在多语言环境中，很难保证所有 Producer 和 Consumer 对消息结构的理解是一致的。
- ​**Avro/Protobuf 的优势**：

  - ​**统一接口**​：它们使用统一的 `.avsc`​ 或 `.proto` 文件定义数据结构。
  - ​**自动生成代码**​：通过工具可以自动为 Java、Python、Go 等语言生成数据类 (DTO)，保证了不同语言实现之间的数据结构​**严格一致**。

### 3. Schema Registry（模式注册中心）

在实际使用 Avro/Protobuf 时，通常会搭配 **Schema Registry** (例如 Confluent Schema Registry) 来使用。

1. ​**注册模式**：Producer 在第一次发送消息前，将其使用的 Avro/Protobuf 模式注册到 Schema Registry。
2. ​**模式 ID**​：Registry 返回一个唯一的​**模式 ID**。
3. ​**序列化**​：Producer 将消息数据进行二进制序列化，并在消息体前部​**添加这个模式 ID**。
4. ​**反序列化**：Consumer 接收消息后，首先读取模式 ID，然后向 Schema Registry 请求对应的完整模式定义。
5. ​**校验**：Consumer 使用获取到的模式定义来正确反序列化消息，并执行兼容性检查。

‍
